{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3. Segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова детектируем края! Вместо  Сanny edge detector, обучите unet-like сетку сегментировать края клеток.\n",
    "\n",
    "В этом задании вам не будет предоставлено практически никакого кода, только входные данные и метрика - interesection-over-union (IoU).\n",
    "\n",
    "Максимальное количество баллов, которое можно будет получить за домашку, - **80**. Дедлайн - 12 июля 23:59.\n",
    "\n",
    "Вам нужно обучить сетку предсказывать маску границ клеток.\n",
    "\n",
    "Используйте все, что вы знаете на данный момент:\n",
    "* Любую архитектуру для семантической сегментации (encoder-decoder или на основе dilated convolusion). Рекомендую использовать UNet.\n",
    "\n",
    "* data augmentation (она точно понадобится поскольку трейн сет состоит только из 41 изображения)\n",
    "\n",
    "* fine-tuning \n",
    "\n",
    "Запрещается делать только одно: обучать сетку на тестовом датасете\n",
    "\n",
    "Засабмитить нужно будет заполненный ноутбук с кодом, с посчитанным значением iou на валидационном датасете, и нарисовать получившиеся изображения для тестового датасета (одноканальное, бинарное изображение, 1 - есть граница, 0 - нету границы).\n",
    "\n",
    "Хорошая сетка должна сегментировать изображения с val iou >= 0.28. Это не строгий критерий для получения полного балла, но попытайтесь получить схожие значения метрики.\n",
    "\n",
    "Практические советы:\n",
    "* На семинаре мы уже реализовали Unet, можете использовать код из семинара. \n",
    "* Скорей всего вы будете создавать собственный класс-датасет как наследник класса `torch.data.utils.Dataset`. Посмотреть, как это  сделать, можно [тут](https://discuss.pytorch.org/t/dataloader-for-semantic-segmentation/48290).\n",
    "* В датасете большой имбаланс классов, поэтому сетка будет выдавать больше \"нулевой\" (не-граница) класс. Чтобы справиться с этой проблемой, следует либо изменить порог при назначении класов (вместо 0.5 выбрать порог поменьше), либо задать веса для классов в лосс-функции (параметр `weights` в `nn.CrossentropyLoss`). Для единичного класса бОльший вес.\n",
    "* У вас маленький датасет, поэтому нужно активно использовать аугментации. Обратите внимание, что если вы используете какие-либо геометрические аугментации (повороты, кропы, флипы, ...) для изображения, ту же самую аугментацию надо выполнять и на маску. Для этого есть два пути: либо кастомизировать пайторчевский датасет (см. [тут](https://discuss.pytorch.org/t/torchvision-transfors-how-to-perform-identical-transform-on-both-image-and-target/10606/5)), либо использовать Albumentations.\n",
    "* По желанию, можно добавить различные пост-процессинг трюки (морфологические операции, локальный трешхолдинг), но лучше посвятить свое время улучшению работы сетки.\n",
    "\n",
    "Удачи!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNJ0DlSRZx5S"
   },
   "outputs": [],
   "source": [
    "### Download the dataset ###\n",
    "!wget https://www.dropbox.com/s/jy34yowcf85ydba/data.zip?dl=0 -O data.zip\n",
    "!unzip -q data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btAFQIMhZx5V"
   },
   "outputs": [],
   "source": [
    "### Visualize the data ###\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# Human HT29 colon-cancer cells\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(1,2,1)\n",
    "im = skimage.img_as_ubyte(io.imread('BBBC018_v1_images-fixed/train/00735-actin.DIB.bmp'))\n",
    "plt.imshow(im)\n",
    "plt.subplot(1,2,2)\n",
    "mask = skimage.img_as_ubyte(io.imread('BBBC018_v1_outlines/train/00735-cells.png'))\n",
    "plt.imshow(mask, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIqI34zlZx5Z"
   },
   "outputs": [],
   "source": [
    "### Target metric ###\n",
    "def calc_iou(prediction, ground_truth):\n",
    "    n_images = len(prediction)\n",
    "    intersection, union = 0, 0\n",
    "    for i in range(n_images):\n",
    "        intersection += np.logical_and(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum() \n",
    "        union += np.logical_or(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum()\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OktocnMv0NvI"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "81qg_hZ8Zx6L",
    "pCJKnRqSZx6N"
   ],
   "name": "homework_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
